{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d223d42d-6b80-4f2b-a154-b532998abd56",
   "metadata": {},
   "source": [
    "Geometric Model Test Implementation\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e9f93-9d32-46c3-8085-5803a3b327ac",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "I managed to get the GCNN working in the latest code, but it's still not performing as well as a regular CNN. Can you take a brief look, if there are any major errors in my configuration?\n",
    "\n",
    "Some quick questions:\n",
    "- I made a custom bug fix in the GSpatialMaxpool to get the shaping correct and a temperary fix with padding size, I hope this is correct?\n",
    "- I have VRAM problems in a 24GB GPU.  I noticed that the GCNN package doesnt support FP16 (type mismatch errors). I think I can implement support, but before I do, is there a technical reason GCNN wouldn't work with FP16 / BF16? Such as not enough precision in FP16?\n",
    "- I imagine in GCNN the default kernel size is 5,  because kernels smaller than 5 has aliasing issues and doesn't record all features across all angles properly?\n",
    "- I remember you mentioning that GConv layers doesn't need as many channels as as equivalent regular Conv, because of the extra operations it does and the more vram it uses? and you can use 25% channels for a fair comparison because of default group kernel of 4?\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad11135e-f2f8-43be-9cfd-1f1fa92d9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import lightning as pl\n",
    "from torch import optim\n",
    "import gconv.gnn as gnn\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "from support import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c29d55f-9f0e-4fdc-bd46-72a58ba48954",
   "metadata": {},
   "source": [
    "# GMaxSpatialPool3D Bug Fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9da48-60ae-48be-a242-328a714004ad",
   "metadata": {},
   "source": [
    "The original GMaxSpatialPool3D provided seem to be bugged in that it doesn't reshape the spatial dimensions correctly. (https://github.com/ThijsKuipers1995/gconv/blob/main/gconv/gnn/modules/pooling.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb266c3-5dbd-4735-9611-9ad7106cc469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 16, 4]' is invalid for input of size 83886080",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m Tensor(np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)))\n\u001b[0;32m      2\u001b[0m x, h \u001b[38;5;241m=\u001b[39m gnn\u001b[38;5;241m.\u001b[39mGLiftingConvSE3(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)(test)\n\u001b[1;32m----> 3\u001b[0m out, h \u001b[38;5;241m=\u001b[39m \u001b[43mgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGMaxSpatialPool3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\PyDev313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\PyDev313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\.conda\\envs\\PyDev313\\Lib\\site-packages\\gconv\\gnn\\modules\\pooling.py:22\u001b[0m, in \u001b[0;36mGMaxSpatialPool3d.forward\u001b[1;34m(self, x, H)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, H: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, H\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[5, 16, 4]' is invalid for input of size 83886080"
     ]
    }
   ],
   "source": [
    "test = Tensor(np.ones((5, 3, 128, 128, 128)))\n",
    "x, h = gnn.GLiftingConvSE3(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 2)(test)\n",
    "out, h = gnn.GMaxSpatialPool3d(2)(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb74d72-c217-4cab-9ada-2251d7548ecc",
   "metadata": {},
   "source": [
    "So I implemented the following as a fix. Not sure if this is the correct way of doing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064b58a1-a2a6-4d69-9a93-6fb98be85452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16, 4, 128, 128, 128])\n",
      "torch.Size([5, 16, 4, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class GMaxSpatialPool3d_fixed(nn.MaxPool3d):\n",
    "    \"\"\"\n",
    "    Performs spatial max pooling on 3d spatial inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x: Tensor, H: Tensor) -> Tensor:\n",
    "               \n",
    "        y = super().forward(x.flatten(1, 2))\n",
    "        D2, H2, W2 = y.shape[-3:]\n",
    "        \n",
    "        return y.view(*x.shape[:3], D2, H2, W2), H\n",
    "\n",
    "\n",
    "test = Tensor(np.ones((5, 3, 128, 128, 128)))\n",
    "x, h = gnn.GLiftingConvSE3(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 2)(test)\n",
    "out, h = GMaxSpatialPool3d_fixed(2)(x, h)\n",
    "\n",
    "print(x.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39fd88-45ea-444b-8248-cb786f29c166",
   "metadata": {},
   "source": [
    "# Padding Inconsistency in GSeparableConvSE3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e103f-bd94-4303-8af7-0a5d4761d7e9",
   "metadata": {},
   "source": [
    "The padding for the GLiftingConvSE3 seems to be working correctly: with a kernel size of 5, padding of 0 reduces size by 4 and a padding of 2 keeps the same shape. This is consistent with the regular torch CONV layers, where padding = (kernel_size - 1)//2. \n",
    "\n",
    "However, the padding parameter for the GSeparableConvSE3 seemed to not working as expected. \n",
    "\n",
    "With a kernel size of 5, a padding of 0 reduces size by 4 like before, but a padding of 2 increases the shape by 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684659d0-3b74-4ac0-972f-1cccb4c27e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 128, 128, 128])\n",
      "torch.Size([5, 16, 4, 128, 128, 128])\n",
      "torch.Size([5, 32, 4, 124, 124, 124])\n",
      "\n",
      "\n",
      "torch.Size([5, 3, 128, 128, 128])\n",
      "torch.Size([5, 16, 4, 128, 128, 128])\n",
      "torch.Size([5, 32, 4, 132, 132, 132])\n"
     ]
    }
   ],
   "source": [
    "test = Tensor(np.ones((5, 3, 128, 128, 128)))\n",
    "\n",
    "x, h = gnn.GLiftingConvSE3(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 2)(test)\n",
    "x1, h2 = gnn.GSeparableConvSE3(16, 32, kernel_size = 5, padding = 0, stride=1)(x, h)\n",
    "\n",
    "\n",
    "print(test.shape)\n",
    "print(x.shape)\n",
    "print(x1.shape)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "test = Tensor(np.ones((5, 3, 128, 128, 128)))\n",
    "\n",
    "x, h = gnn.GLiftingConvSE3(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 2)(test)\n",
    "x1, h2 = gnn.GSeparableConvSE3(16, 32, kernel_size = 5, padding = 2, stride=1)(x, h)\n",
    "\n",
    "\n",
    "print(test.shape)\n",
    "print(x.shape)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506783d-8496-4958-94a7-f89922b0d139",
   "metadata": {},
   "source": [
    "This means the GSeparableConvSE3 layer does some internal handling of padding, and I was able to get the shape to match by using a custom padding formula: (padding = (kernel_size - 1)//2 - 1).\n",
    "\n",
    "In this case, to keep the same shape with kernel size = 5, the padding needs to be set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621325e7-bf11-4605-bb65-2245c245bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 128, 128, 128])\n",
      "torch.Size([5, 16, 4, 128, 128, 128])\n",
      "torch.Size([5, 32, 4, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "test = Tensor(np.ones((5, 3, 128, 128, 128)))\n",
    "\n",
    "x, h = gnn.GLiftingConvSE3(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 2)(test)\n",
    "x1, h2 = gnn.GSeparableConvSE3(16, 32, kernel_size = 5, padding = 1, stride=1)(x, h)\n",
    "\n",
    "\n",
    "print(test.shape)\n",
    "print(x.shape)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416fa8f-f06f-4732-b112-fa9079eccbd1",
   "metadata": {},
   "source": [
    "# Testing with a basic regression network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63504ed-26fc-459c-b27c-6d28a6cd68c2",
   "metadata": {},
   "source": [
    "Below is a basic GCNN regressor with Lifting, GConv, GSpatialMaxPool, GAvgGlobalPool, and a regular regression head with standard CNN layers. \n",
    "\n",
    "It doesn't regress quite as well a regular CNN. I hope there isn't a major problem in the configuration / structure of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25157d31-c15a-47da-aaa9-ea17202e0a65",
   "metadata": {},
   "source": [
    "Training progress & results can be found in attached HTML: https://github.com/0-CWANG-0/GCNNtest/blob/main/GCNN_regression.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a71443a-63b9-4e11-9b25-2394ad2dedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geometric_conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, \n",
    "                       mid_channels, \n",
    "                       out_channels, \n",
    "                       kernel_size = 5,\n",
    "                       stride= 1):\n",
    "        \n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2 - 1\n",
    "        \n",
    "        self.gconv1_internal = gnn.GSeparableConvSE3(in_channels, \n",
    "                                                     mid_channels, \n",
    "                                                     kernel_size = kernel_size,\n",
    "                                                     padding = padding,\n",
    "                                                     stride=1)\n",
    "        self.normalization_1 = gnn.GBatchNorm3d(mid_channels)\n",
    "        self.activation_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.gconv2_internal = gnn.GSeparableConvSE3(mid_channels, \n",
    "                                                     out_channels, \n",
    "                                                     kernel_size = kernel_size,\n",
    "                                                     padding = padding,\n",
    "                                                     stride=stride)\n",
    "        self.normalization_2 = gnn.GBatchNorm3d(out_channels)\n",
    "        self.activation_2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x, H):\n",
    "        \n",
    "        x, H = self.gconv1_internal(x, H)  \n",
    "        #x, H = self.normalization_1(x, H)         \n",
    "        x = self.activation_1(x)\n",
    "        \n",
    "        x, H = self.gconv2_internal(x, H)\n",
    "        #x, H = self.normalization_2(x, H)\n",
    "        x = self.activation_2(x)\n",
    "        \n",
    "        return x, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ee95cb-2d20-4018-af5c-c0e1ec2a6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geometric_basic_regressor_3D(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 loss_func = \"mse\",  \n",
    "                 learning_rate = 0.0001,\n",
    "                 input_channels = 1,\n",
    "                 output_channels = 1,\n",
    "                 mlp_hidden = 256,\n",
    "                 dropout_p = 0.0):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # lifting to SE3\n",
    "        self.lifting_layer = gnn.GLiftingConvSE3(in_channels = input_channels,\n",
    "                                                 out_channels = 16,\n",
    "                                                 kernel_size = 5,\n",
    "                                                 padding = 2)\n",
    "\n",
    "        # Define the encoding layers\n",
    "        self.encoder1 = geometric_conv_block(16, 16, 32, kernel_size = 5)\n",
    "        self.maxpooler1 = GMaxSpatialPool3d_fixed(2)\n",
    "        \n",
    "        self.encoder2 = geometric_conv_block(32, 32, 64, kernel_size = 5)\n",
    "        self.maxpooler2 = GMaxSpatialPool3d_fixed(2)\n",
    "        \n",
    "        self.encoder3 = geometric_conv_block(64, 64, 128, kernel_size = 5)\n",
    "        self.maxpooler3 = GMaxSpatialPool3d_fixed(2)\n",
    "        \n",
    "        self.encoder4 = geometric_conv_block(128, 128, 256, kernel_size = 5)\n",
    "\n",
    "    \n",
    "        # Define the regression layers\n",
    "        self.global_pool = gnn.GAvgGlobalPool()\n",
    "        self.regressor = nn.Sequential(nn.Flatten(),                      \n",
    "                                       nn.Linear(256, mlp_hidden),\n",
    "                                       nn.LayerNorm(mlp_hidden),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Dropout(dropout_p) if dropout_p > 0 else nn.Identity(),\n",
    "                                       nn.Linear(mlp_hidden, output_channels)\n",
    "                                       )\n",
    "        nn.init.uniform_(self.regressor[-1].weight, -1e-3, 1e-3)\n",
    "        nn.init.zeros_(self.regressor[-1].bias)\n",
    "\n",
    "        self.loss_func = loss_func.lower()\n",
    "        if self.loss_func not in {\"mse\", \"l1\", \"smoothl1\"}:\n",
    "            raise ValueError(\"Invalid loss type. Use 'mse', 'l1', or 'smoothl1'.\")\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # lifting SE3\n",
    "        x, H = self.lifting_layer(x)\n",
    "        \n",
    "        # Encodor\n",
    "        x, H = self.encoder1(x, H)\n",
    "        x, H = self.maxpooler1(x, H)\n",
    "        x, H = self.encoder2(x, H)\n",
    "        x, H = self.maxpooler2(x, H)\n",
    "        x, H = self.encoder3(x, H)\n",
    "        x, H = self.maxpooler3(x, H)\n",
    "        x, H = self.encoder4(x, H)\n",
    "        \n",
    "        # regressor\n",
    "        features = self.global_pool(x, H)\n",
    "        out  = self.regressor(features.float())     \n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        # corrects shape\n",
    "        if y.ndim == 1:\n",
    "            y = y.unsqueeze(-1)\n",
    "        y = y.float()\n",
    "\n",
    "        preds = self(x)\n",
    "        loss  = self.compute_loss(preds, y)\n",
    "    \n",
    "        #mae = torch.mean(torch.abs(preds - y))\n",
    "        \n",
    "        # MAPE (%)\n",
    "        denom = y.abs().clamp_min(1e-8)\n",
    "        mape  = 100.0 * torch.mean(torch.abs((preds - y) / denom))\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=False, on_step=True)\n",
    "        self.log(\"train_mape\", mape, prog_bar=True, on_epoch=False, on_step=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "    \n",
    "        if y.ndim == 1:\n",
    "            y = y.unsqueeze(-1)\n",
    "        y = y.float()\n",
    "\n",
    "        preds = self(x)\n",
    "        loss  = self.compute_loss(preds, y)\n",
    "\n",
    "        #mae = torch.mean(torch.abs(preds - y))\n",
    "        \n",
    "        denom = y.abs().clamp_min(1e-8)\n",
    "        mape  = 100.0 * torch.mean(torch.abs((preds - y) / denom))\n",
    "        \n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_epoch=True, on_step=True)\n",
    "        self.log(\"valid_mape\", mape, prog_bar=True, on_epoch=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                         mode='min', \n",
    "                                                         patience=3, \n",
    "                                                         factor=0.2\n",
    "                                                         )\n",
    "        return {\"optimizer\": optimizer, \n",
    "                \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"valid_loss\"}}\n",
    "\n",
    "\n",
    "    \n",
    "    def compute_loss(self, preds, targets):\n",
    "        preds = preds.float()\n",
    "        targets = targets.float()\n",
    "        if self.loss_func == \"mse\":\n",
    "            return nn.MSELoss()(preds, targets)\n",
    "        elif self.loss_func == \"l1\":\n",
    "            return nn.L1Loss()(preds, targets)\n",
    "        elif self.loss_func == \"smoothl1\":\n",
    "            return nn.SmoothL1Loss(beta=0.5)(preds, targets)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66b67d-1309-4f5b-bee0-c6218831d601",
   "metadata": {},
   "source": [
    "# Testing with UNet for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aedc87-41f6-4f5c-8c0a-f57e3e4385ac",
   "metadata": {},
   "source": [
    "I then tried with a segmentation. This one I struggle with VRAM, even on a 24GB GPU, and I can only run with batch size 1 and lowering the channel sizes significantly. I might implement FP16 mixed precision support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53dc3579-3a27-46a9-a040-cbc912e9570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geometric_conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, \n",
    "                       mid_channels, \n",
    "                       out_channels, \n",
    "                       kernel_size = 5,\n",
    "                       stride= 1):\n",
    "        \n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2 - 1\n",
    "        \n",
    "        self.gconv1_internal = gnn.GSeparableConvSE3(in_channels, \n",
    "                                                     mid_channels, \n",
    "                                                     kernel_size = kernel_size,\n",
    "                                                     padding = padding,\n",
    "                                                     stride=1)\n",
    "        self.normalization_1 = gnn.GBatchNorm3d(mid_channels)\n",
    "        self.activation_1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.gconv2_internal = gnn.GSeparableConvSE3(mid_channels, \n",
    "                                                     out_channels, \n",
    "                                                     kernel_size = kernel_size,\n",
    "                                                     padding = padding,\n",
    "                                                     stride=stride)\n",
    "        self.normalization_2 = gnn.GBatchNorm3d(out_channels)\n",
    "        self.activation_2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x, H):\n",
    "        \n",
    "        x, H = self.gconv1_internal(x, H)  \n",
    "        x, H = self.normalization_1(x, H)         \n",
    "        x = self.activation_1(x)\n",
    "        \n",
    "        x, H = self.gconv2_internal(x, H)\n",
    "        x, H = self.normalization_2(x, H)\n",
    "        x = self.activation_2(x)\n",
    "        \n",
    "        return x, H\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class geometric_upconv_block(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size = 3,\n",
    "                 scale_factor = (2, 2, 2),\n",
    "                 align_corners = False):\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        padding = (kernel_size - 1) // 2 - 1\n",
    "\n",
    "        \n",
    "        self.scale_factor = scale_factor\n",
    "        self.align_corners = align_corners\n",
    "        \n",
    "\n",
    "        self.gconv_internal = gnn.GSeparableConvSE3(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size = kernel_size,\n",
    "                                                    padding = padding)\n",
    "        \n",
    "        self.normalization_internal = gnn.GBatchNorm3d(out_channels)\n",
    "        \n",
    "        self.relu_internal = nn.ReLU(inplace = True)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, H: torch.Tensor):\n",
    "        # x: (B, C, R, D, H, W)\n",
    "        B, C, R, D, Hs, Ws = x.shape\n",
    "\n",
    "        # Merge (C, R)\n",
    "        x_cr = x.flatten(1, 2)  # (B, C*R, D, H, W)\n",
    "        x_cr = F.interpolate(x_cr,\n",
    "                             scale_factor = self.scale_factor,\n",
    "                             mode = 'trilinear',\n",
    "                             align_corners = self.align_corners)\n",
    "\n",
    "        # Restore group dim R\n",
    "        D2, H2, W2 = x_cr.shape[-3:]\n",
    "        x_up = x_cr.contiguous().view(B, C, R, D2, H2, W2)\n",
    "\n",
    "        # Equivariant conv + norm + act\n",
    "        x_up, H = self.gconv_internal(x_up, H)\n",
    "        x_up, H = self.normalization_internal(x_up, H)\n",
    "        x_up = self.relu_internal(x_up)\n",
    "        \n",
    "        return x_up, H\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Geometric_UNet3D(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 learning_rate=0.0001,\n",
    "                 input_channels = 2,\n",
    "                 first_kernel_size = 5):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        \n",
    "        self.first_kernel_size = first_kernel_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "        # initial lifting\n",
    "        self.padding_first = (self.first_kernel_size - 1) // 2\n",
    "        \n",
    "        \n",
    "        self.lifting_layer = gnn.GLiftingConvSE3(in_channels = input_channels,\n",
    "                                                 out_channels = 16,\n",
    "                                                 kernel_size = self.first_kernel_size,\n",
    "                                                 padding = self.padding_first)\n",
    "        \n",
    "        # Define the 3D U-Net layers (encoder)\n",
    "        self.encoder1 = geometric_conv_block(16, 16, 16, \n",
    "                                             kernel_size = self.first_kernel_size)\n",
    "        self.maxpooler1 = GMaxSpatialPool3d_fixed(2)\n",
    "        \n",
    "        self.encoder2 = geometric_conv_block(16, 16, 32, \n",
    "                                             kernel_size = 5)\n",
    "        self.maxpooler2 = GMaxSpatialPool3d_fixed(2)\n",
    "        \n",
    "        self.encoder3 = geometric_conv_block(32, 32, 32, \n",
    "                                             kernel_size = 5)\n",
    "        self.maxpooler3 = GMaxSpatialPool3d_fixed(2)\n",
    "        \n",
    "        self.encoder4 = geometric_conv_block(32, 64, 64, \n",
    "                                             kernel_size = 5)\n",
    "        \n",
    "        self.upconv1 = geometric_upconv_block(64, \n",
    "                                              64,\n",
    "                                              kernel_size = 5,\n",
    "                                              scale_factor = 2,\n",
    "                                              align_corners = False)\n",
    "\n",
    "        \n",
    "        # Define the 3D U-Net layers (decoder)\n",
    "        self.decoder1 = geometric_conv_block(64 + 32, 32, 32, \n",
    "                                             kernel_size = 5)\n",
    "        self.upconv2 = geometric_upconv_block(32, \n",
    "                                              32,\n",
    "                                              kernel_size = 5,\n",
    "                                              scale_factor = 2,\n",
    "                                              align_corners = False)\n",
    "            \n",
    "            \n",
    "        self.decoder2 = geometric_conv_block(32 + 32, 16, 16, \n",
    "                                             kernel_size = 5)\n",
    "        self.upconv3 = geometric_upconv_block(16, \n",
    "                                              16,\n",
    "                                              kernel_size = 5,\n",
    "                                              scale_factor = 2,\n",
    "                                              align_corners = False)\n",
    "            \n",
    "        self.decoder3 = geometric_conv_block(16+16, 16, 16, \n",
    "                                             kernel_size = 5)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.group_pool = gnn.GAvgGroupPool() \n",
    "\n",
    "        # segmentation classification\n",
    "        self.final_conv = nn.Conv3d(16, 1, kernel_size = 1)\n",
    "\n",
    "        # sigmoid output for segmentation\n",
    "        self.final_conv_activation = nn.Sigmoid()\n",
    "            \n",
    "        \n",
    "        # applies HE normal initialization\n",
    "        init.kaiming_normal_(self.final_conv.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if self.final_conv.bias is not None:\n",
    "            init.zeros_(self.final_conv.bias)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # lifting layer\n",
    "        x, H = self.lifting_layer(x)                 \n",
    "\n",
    "        # Encoding path\n",
    "        enc1, H = self.encoder1(x, H)               \n",
    "        mpl1, H = self.maxpooler1(enc1, H)          \n",
    "        \n",
    "        enc2, H = self.encoder2(mpl1, H)             \n",
    "        mpl2, H = self.maxpooler2(enc2, H)\n",
    "        \n",
    "        enc3, H = self.encoder3(mpl2, H)           \n",
    "        mpl3, H = self.maxpooler3(enc3, H)\n",
    "        \n",
    "        enc4, H = self.encoder4(mpl3, H)           \n",
    "        \n",
    "        # Decoding path\n",
    "        upc1, H = self.upconv1(enc4, H)              \n",
    "        conc1 = torch.cat([enc3, upc1], dim=1)       \n",
    "        dec1, H = self.decoder1(conc1, H)            \n",
    "        \n",
    "        upc2, H = self.upconv2(dec1, H)              \n",
    "        conc2 = torch.cat([enc2, upc2], dim=1)       \n",
    "        dec2, H = self.decoder2(conc2, H)            \n",
    "        \n",
    "        upc3, H = self.upconv3(dec2, H)            \n",
    "        conc3 = torch.cat([enc1, upc3], dim=1)       \n",
    "        dec3, H = self.decoder3(conc3, H)            \n",
    "\n",
    "        # projection\n",
    "        dec3_project = self.group_pool(dec3)          \n",
    "        \n",
    "        # segmentation prediction path   \n",
    "        out = self.final_conv(dec3_project)           \n",
    "        out = self.final_conv_activation(out)     \n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.contiguous()\n",
    "        y = y.contiguous()\n",
    "        \n",
    "        preds = self(x)\n",
    "        loss = self.compute_loss(preds, y)\n",
    "        \n",
    "        acc = self.accuracy(preds, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=False, on_step=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=False, on_step=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.contiguous()\n",
    "        y = y.contiguous()\n",
    "        \n",
    "        preds = self(x)\n",
    "        loss = self.compute_loss(preds, y)\n",
    "        \n",
    "        acc = self.accuracy(preds, y)\n",
    "        \n",
    "        self.log(\"valid_loss\", loss, prog_bar=True, on_epoch=True, on_step=True)\n",
    "        self.log(\"valid_acc\", acc, prog_bar=True, on_epoch=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                         mode='min', \n",
    "                                                         patience=3, \n",
    "                                                         factor=0.2\n",
    "                                                         )\n",
    "        return {\"optimizer\": optimizer, \n",
    "                \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"valid_loss\"}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute_loss(self, preds, targets):\n",
    "\n",
    "        loss = IoU_Loss_torch()(preds, targets)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def accuracy(self, preds, targets):\n",
    "        \n",
    "        # Convert predictions to binary (0 or 1)\n",
    "        preds = preds > 0.5\n",
    "        targets = targets > 0.5\n",
    "        \n",
    "        # Flatten the tensors to compute accuracy\n",
    "        preds = preds.view(preds.size(0), -1)\n",
    "        targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "   \n",
    "        # Calculate accuracy per image in the batch\n",
    "        correct_per_image = (preds == targets).sum(dim=1).float()  # Correct predictions per image\n",
    "        total_per_image = preds.size(1)  # Number of elements per image\n",
    "\n",
    "        # Compute accuracy for each image in the batch\n",
    "        accuracy_per_image = correct_per_image / total_per_image\n",
    "        \n",
    "        \n",
    "        return accuracy_per_image.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
